{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54699955",
   "metadata": {},
   "source": [
    "## ABSTRACT\n",
    "\n",
    "Contained below is a functional twitter bot that accesses tweets via the Tweepy library and Twitter API. The connection is first intialized using API, Bearer, and Clent keys/IDs. Once verified, two functions are created.\n",
    "\n",
    "1. Search_Tweets()\n",
    "\n",
    "Used to scrape all tweets in the explore page that contain one of the keywords specified in the argument list. For this project's purpose those keywords were centered around finding job posts via twitter for jobs in the sports market. This is not a perfect method of finding job postings nor is twitter the ideal platform as many tweets are subjective and opinionated thus resulting in an endless amount of variations of verbiage. In other words, the texts scraped from twitter could use a combination of the words job, hire, and resume for purposes other than actual employment. This function returns three arrays:\n",
    "\n",
    "1. tweet_results - Contains information regarding individual tweets that meet the keyword criteria. Some info includes tweet id, tweet date/time, tweet contents and URLS if any. \n",
    "\n",
    "2. twitter_user_results - Contains information regarding the users of each tweet including but not limited to user id/name/username, user location, and user join date.\n",
    "\n",
    "3. tweet_mention_results - Contains information regarding users mentioned in tweets in case a recruiter or imortant figure is mentioned. These fields are tweet id, tweet user id, and the username of the mentioned account.\n",
    "\n",
    "2. User_Timeline()\n",
    "\n",
    "Defined to pull tweets from all unique users pulled via Search_Tweets(). This function returns an identical array to tweet_results so that the two can be later combined into one table of tweets and tweet info. The one returned field is:\n",
    "\n",
    "1. user_tweets - Contains identical info to tweet_results for all tweets by all users gathered in function 1 but only from the past 24 hours. \n",
    "\n",
    "Finally a tibble is created containing the value 1 and the string \"Twitter\". This tibble called Sources is created with future data scraping in mind as job postings can be referenced by a source ID which states where the post was pulled from.\n",
    "\n",
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "Once gathered, the data is passed into the SQL database which is created via the Python/MYSQL connection established using pymysql. The execute_query function is the only function defined for this portion to allow each query to be executed and a message to display if succesful.\n",
    "\n",
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "This bot works appropriately however as previously mentioned is not ideal for job searching. Improvements could be expanding the search for greater than 24 hours and to clean out irrelvant or subjective tweets. For an example of a subjective tweet issue read the below scenario:\n",
    "\n",
    "Scenario 1\n",
    "\n",
    "If a twitter user did not like an NFL player or coach's performace in a game they may tweet, \"Wow what a terrible call by THIS SPECIFIC NFL COACH, they deserve to be out of a Job!! @NFLTEAM let me know when you are hiring for a new head coach because Id like to apply and my resume is astounding!\". While that twitter user may not be even remotely qualified nor serious about the tweet, this specific tweet would trigger keywords such as 'Job','hiring','apply', and even 'resume'. This is just one example of how difficult twitter scraping can be when looking for serious objective content.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libraries and storing API Keys as a comments for reference\n",
    "\n",
    "\n",
    "# API KEY: FB7QAHPem56r0Mv83RKuPJR4Y\n",
    "# API KEY SECRET: r7j3GMhjRIXtXjkNnlypjqQW60jDTkojPBPcieQlahdTHr3Q9h\n",
    "# BEARER TOKEN: AAAAAAAAAAAAAAAAAAAAAMuRiQEAAAAASfWfjQlkVEO7bLR%2B2LI%2FS8s42Eo%3D4dXlyGNYxVfKk2QD1kW4C3GmDZgSZuuFbF8XYbBaC3Aqi6AZSJ\n",
    "# Client ID: UkxpeUtFN0pDanNWRS1tSk9ZTXY6MTpjaQ\n",
    "# Client Secret: wTSnz2QkfIittU70Vw0rhKFm6FTjkTbeMTHzZXUUwHK4rcd7S_\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import datetime, time\n",
    "import pytz\n",
    "#!pip install wget\n",
    "import wget\n",
    "#!pip install -- tweepy\n",
    "import tweepy\n",
    "## !pip install mysql.connector\n",
    "# import mysql.connector\n",
    "## !pip install pymysql\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import MySQLdb\n",
    "import xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad918691",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installation / Access to Twitter Account, Prints Authentification Succesful if connection is valid\n",
    "\n",
    "consumer_key = 'FB7QAHPem56r0Mv83RKuPJR4Y'\n",
    "consumer_secret = 'r7j3GMhjRIXtXjkNnlypjqQW60jDTkojPBPcieQlahdTHr3Q9h'\n",
    "access_token = '1583139235342811138-CNcRKakrtwYsJdRhjNvUqXsrE6mha8'\n",
    "access_token_secret = '1kpR1zSr9wlE1wk8MexeytDHlTzUgBM31qzNsSmF4mzlX'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication Succesful\")\n",
    "except:\n",
    "    print(\"Error during authentication, check keys and try again!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda302e",
   "metadata": {},
   "source": [
    "# Once Authenticated Functions are Defined as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to search for the keywords and retrieve tweet contents and properties as well as user information. Returns two \n",
    "## lists one for tweet info and one for user info.\n",
    "\n",
    "def search_tweets(keywords):\n",
    "    tweet_results = []\n",
    "    twitter_user_results = []\n",
    "    tweet_mention_results = []\n",
    "    i = 0\n",
    "    for query in keywords:\n",
    "        \n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q = query, count=5,\n",
    "                              tweet_mode = 'extended').items():\n",
    "            \n",
    "            if tweet.full_text.startswith('RT @'):\n",
    "                pass\n",
    "                #text = tweet.retweeted_status.full_text\n",
    "                #tweet_results.append(s + 'RT @' + text)\n",
    "            else:\n",
    "                i += 1\n",
    "                s = (i)\n",
    "                \n",
    "                if(tweet.entities['user_mentions'] == []):\n",
    "                    if tweet.entities['urls'] == []:\n",
    "                        tweet_results.append([s, tweet.id, tweet.full_text, tweet.created_at, tweet.place, tweet.retweet_count, tweet.favorite_count, \"NO URLS\", query])\n",
    "                \n",
    "                        twitter_user_results.append([tweet.user.id, tweet.user.screen_name, tweet.user.name, tweet.user.description, \n",
    "                                      tweet.user.location, tweet.user.created_at, tweet.user.favourites_count, tweet.user.followers_count, tweet.user.friends_count, \n",
    "                                      tweet.user.profile_image_url])\n",
    "\n",
    "                        tweet_mention_results.append([tweet.id,tweet.user.id, 'No Mentions'])\n",
    "                \n",
    "                    else:\n",
    "                        tweet_results.append([s, tweet.id, tweet.full_text, tweet.created_at, tweet.place, tweet.retweet_count, tweet.favorite_count, tweet.entities['urls'][0]['url'], query])\n",
    "                \n",
    "                        twitter_user_results.append([tweet.user.id, tweet.user.screen_name, tweet.user.name, tweet.user.description, \n",
    "                                      tweet.user.location, tweet.user.created_at, tweet.user.favourites_count, tweet.user.followers_count, tweet.user.friends_count, \n",
    "                                      tweet.user.profile_image_url])\n",
    "\n",
    "                        tweet_mention_results.append([s, tweet.id,tweet.user.id, 'No Mentions'])\n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    if tweet.entities['urls'] == []:\n",
    "                        tweet_results.append([s, tweet.id, tweet.full_text, tweet.created_at, tweet.place, tweet.retweet_count, tweet.favorite_count, \"NO URLS\", query])\n",
    "                \n",
    "                        twitter_user_results.append([tweet.user.id, tweet.user.screen_name, tweet.user.name, tweet.user.description, \n",
    "                                      tweet.user.location, tweet.user.created_at, tweet.user.favourites_count, tweet.user.followers_count, tweet.user.friends_count, \n",
    "                                      tweet.user.profile_image_url])\n",
    "                \n",
    "                        tweet_mention_results.append([tweet.id,tweet.user.id, tweet.entities['user_mentions'][0]['screen_name']])\n",
    "                \n",
    "                    else:\n",
    "                        tweet_results.append([s, tweet.id, tweet.full_text, tweet.created_at, tweet.place, tweet.retweet_count, tweet.favorite_count, tweet.entities['urls'][0]['url'], query])\n",
    "                \n",
    "                        twitter_user_results.append([tweet.user.id, tweet.user.screen_name, tweet.user.name, tweet.user.description, \n",
    "                                      tweet.user.location, tweet.user.created_at, tweet.user.favourites_count, tweet.user.followers_count, tweet.user.friends_count, \n",
    "                                      tweet.user.profile_image_url])\n",
    "                \n",
    "                        tweet_mention_results.append([s, tweet.id, tweet.user.id, tweet.entities['user_mentions'][0]['screen_name']])\n",
    "                \n",
    "    return(tweet_results,twitter_user_results,tweet_mention_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to search all users and pull their tweets over the last 24 hours. Returns same info as tweet table in other func\n",
    "\n",
    "def user_timeline(user_names):\n",
    "    user_tweets = []\n",
    "    \n",
    "    print(user_names)\n",
    "    \n",
    "    now = datetime.datetime.today()\n",
    "    date_since = datetime.datetime.strptime(time.strftime(\"%Y-%m-%d\"), \"%Y-%m-%d\")\n",
    "    day_ago_pre = now - datetime.timedelta(hours=24)\n",
    "    day_ago = day_ago_pre.replace(tzinfo=pytz.utc)\n",
    "    \n",
    "    for name in user_names:\n",
    "        count = 0\n",
    "        try:\n",
    "            for tweet in tweepy.Cursor(api.user_timeline, screen_name = name,\n",
    "                                      tweet_mode = 'extended').items():\n",
    "            \n",
    "                if tweet.full_text.startswith('RT @'):\n",
    "                    pass\n",
    "            \n",
    "                elif (tweet.created_at < day_ago):\n",
    "                    break\n",
    "            \n",
    "                else:\n",
    "                    count = count + 1\n",
    "                    if tweet.entities['urls'] == []:\n",
    "                        user_tweets.append([count, tweet.id, tweet.full_text, tweet.created_at, tweet.place, tweet.retweet_count, tweet.favorite_count, 'NO URLS', tweet.user.id])\n",
    "                    else:\n",
    "                        user_tweets.append([count, tweet.id, tweet.full_text, tweet.created_at, tweet.place, tweet.retweet_count, tweet.favorite_count, tweet.entities['urls'][0]['url'], tweet.user.id])\n",
    "        except:\n",
    "            pass\n",
    "    return(user_tweets)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54fe7e04",
   "metadata": {},
   "source": [
    "## Initializing dataframes\n",
    "# UPDATE: REMOVED BECAUSE DEEMED NOT NECESSARY\n",
    "\n",
    "#Tweets_df = pd.DataFrame(columns = ['index', 'tweet_ID', 'tweet_contents', 'tweet_date_time', 'tweet_location', 'keywords'])\n",
    "#Tweet_User_df = pd.DataFrame(columns = ['user_id', 'user_Handle','user_name','user_bio','user_location','user_follower_count','user_friend_count','twitter_profile_img_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e63a31",
   "metadata": {},
   "source": [
    "# Once Functions are completed, Data is Collected as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac91c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works 100% with few keywords, Rate Limit Not accounted for Yet\n",
    "keywords_list = [\"following roles sports\",\"Job Opportunity Sports\", \"Jobs in Sports\",\"SoccerJobs\"]\n",
    "tweet_search_rs,tweet_user_rs, tweet_mention_rs = search_tweets(keywords_list)\n",
    "##\"Football Jobs\", \"Basketball Jobs\", \"Baseball Jobs\", \"Job Alert MLS\", \"Job Alert NFL\", \"Job Alert NBA\", \"Job Alert MLB\", \"Job Alert Premier League\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_df = pd.DataFrame(tweet_search_rs, columns = ['index', 'tweet_ID', 'tweet_contents', 'tweet_date_time', 'tweet_location','tweet_rt_count','tweet_fav_count', 'tweet_urls', 'keywords'])\n",
    "\n",
    "Tweet_User_df = pd.DataFrame(tweet_user_rs,columns = ['user_ID', 'user_handle','user_name','user_bio','user_location','user_join_date','user_fav_count','user_follower_count','user_following_count','twitter_profile_img_url'])\n",
    "\n",
    "Tweet_Mentions_df = pd.DataFrame(tweet_mention_rs, columns = ['mention_row_ID','tweet_ID', 'source_user_ID', 'mentioned_user'])\n",
    "\n",
    "Tweets_df['tweet_user_ID'] = (Tweet_User_df['user_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6940c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets_rs = user_timeline(Tweet_User_df.user_handle.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be273d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Tweets_df = pd.DataFrame(user_tweets_rs, columns = ['index', 'tweet_ID', 'tweet_contents', 'tweet_date_time', 'tweet_location','tweet_rt_count','tweet_fav_count', 'tweet_urls', 'tweet_user_ID'])\n",
    "User_Tweets_df['keywords'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ceb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Tweets_df = User_Tweets_df.reindex(columns = ['tweet_ID', 'tweet_user_ID', 'tweet_contents', 'tweet_date_time', 'tweet_location','tweet_rt_count','tweet_fav_count', 'tweet_urls', 'keywords'])\n",
    "Tweets_df = Tweets_df.reindex(columns = ['tweet_ID', 'tweet_user_ID', 'tweet_contents', 'tweet_date_time', 'tweet_location','tweet_rt_count','tweet_fav_count', 'tweet_urls', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_Final_df = pd.concat([Tweets_df,User_Tweets_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_Final_df['source_identifier'] = 1\n",
    "Tweets_Final_df = Tweets_Final_df[(Tweets_Final_df.duplicated(['tweet_ID'])) == False]\n",
    "Tweet_Mentions_df = Tweet_Mentions_df[(Tweet_Mentions_df.duplicated(['tweet_ID'])) == False]\n",
    "Tweet_User_df = Tweet_User_df[(Tweet_User_df.duplicated(['user_ID'])) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece95672",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_Final_df['tweet_contents'] = Tweets_Final_df['tweet_contents'].str.replace(\"'\",\"\").str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sources = pd.DataFrame({'source_ID': [1], 'source_name': ['Twitter']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0039a1b",
   "metadata": {},
   "source": [
    "# With the Data Collected, the database connection is established and all data is imported as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize connection to MYSQL\n",
    "database = MySQLdb.connect(host=\"localhost\" , user=\"root\" , passwd=\"Pps11844\")\n",
    "cursor = database.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de283271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query_statement):\n",
    "    try:\n",
    "        cursor.execute(query_statement);\n",
    "        database.commit();\n",
    "        print(\"Data is Succefully Inserted\")\n",
    "    \n",
    "    except Exception as e :\n",
    "        database.rollback();\n",
    "        print(\"The  Exception Occured : \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(query_statement = (\"CREATE Database IF NOT EXISTS JobsinSports\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37733da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(\"USE JobsinSports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only used to delete and edit schema during Debugging phase \n",
    "#execute_query(\"DROP DATABASE JobsinSports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d60c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(\"CREATE TABLE IF NOT EXISTS Tweets(tweet_ID BIGINT PRIMARY KEY NOT NULL UNIQUE, tweet_user_ID BIGINT NOT NULL, tweet_contents TEXT, tweet_date_time DATETIME, tweet_location TEXT, tweet_rt_count INT, tweet_fav_count INT, tweet_urls VARCHAR(255), keywords VARCHAR(100) DEFAULT NULL, source_identifier INT DEFAULT 0);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9282c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(\"CREATE TABLE IF NOT EXISTS Sources(source_ID BIGINT PRIMARY KEY NOT NULL UNIQUE, source_name VARCHAR(55));\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(\"CREATE TABLE IF NOT EXISTS Tweet_User(user_ID BIGINT PRIMARY KEY NOT NULL UNIQUE, user_handle VARCHAR(25) NOT NULL UNIQUE, user_name VARCHAR(100), user_bio VARCHAR(255), user_location TEXT, user_join_date DATETIME, user_fav_count INT, user_follower_count INT, user_following_count INT, twitter_profile_img_url VARCHAR(255));\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(\"CREATE TABLE IF NOT EXISTS Tweet_Mentions(mention_row_ID INT PRIMARY KEY NOT NULL UNIQUE, source_tweet_ID BIGINT, source_user_ID BIGINT, mentioned_user VARCHAR(100));\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in Sources.iterrows():\n",
    "    execute_query('INSERT INTO Sources (source_ID, source_name) VALUES (%d, \"%s\")' % (j['source_ID'],j['source_name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff311418",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in Tweet_User_df.iterrows():\n",
    "    execute_query('INSERT INTO Tweet_User (user_ID, user_handle, user_name, user_bio, user_location, user_join_date, user_fav_count, user_follower_count, user_following_count, twitter_profile_img_url) VALUES (%d, \"%s\", \"%s\", \"%s\", \"%s\", \"%s\", %d, %d, %d, \"%s\")' % (j['user_ID'], j['user_handle'], j['user_name'], j['user_bio'], j['user_location'], j['user_join_date'], j['user_fav_count'], j['user_follower_count'], j['user_following_count'], j['twitter_profile_img_url']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d426a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tweets_df.shape\n",
    "\n",
    "for i,j in Tweets_Final_df.iterrows():\n",
    "    execute_query('INSERT INTO Tweets (tweet_ID, tweet_user_ID, tweet_contents, tweet_date_time, tweet_location, tweet_rt_count, tweet_fav_count, tweet_urls, keywords, source_identifier) VALUES (%d, %d, \"%s\", \"%s\", \"%s\", %d, %d, \"%s\", \"%s\", %d)' % (j['tweet_ID'], j['tweet_user_ID'], j['tweet_contents'], j['tweet_date_time'], j['tweet_location'],j['tweet_rt_count'],j['tweet_fav_count'], j['tweet_urls'], j['keywords'],j['source_identifier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in Tweet_Mentions_df.iterrows():\n",
    "    try:\n",
    "        execute_query('INSERT INTO Tweet_Mentions (mention_row_ID, source_tweet_ID, source_user_ID, mentioned_user) VALUES (%d, %d, %d,\"%s\")' % (j['mention_row_ID'],j['tweet_ID'], j['source_user_ID'], j['mentioned_user']))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
